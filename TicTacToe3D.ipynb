{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WinCondition:\n",
    "    def __init__(self, board=[[[]]], size=4):\n",
    "        self.win_player = \"X\"\n",
    "        self.board = board\n",
    "        self.size = size\n",
    "\n",
    "    def check_win(self):\n",
    "        layers = self.check_all_layers()\n",
    "        z_check = self.check_all_z()\n",
    "        diag = self.check_cross_diagonals() or self.check_all_vertical_diagonals()\n",
    "\n",
    "        return diag or z_check or layers\n",
    "\n",
    "    def check_all_layers(self):\n",
    "        return any(self.check_layer(z) for z in range(self.size))\n",
    "\n",
    "    def check_all_z(self):\n",
    "        return any(self.check_z(x, y) for x in range(self.size) for y in range(self.size))\n",
    "\n",
    "    def check_all_vertical_diagonals(self):\n",
    "        xdiag = any(self.check_vertical_xdiagonals(x) for x in range(self.size))\n",
    "        ydiag = any(self.check_vertical_ydiagonals(y) for y in range(self.size))\n",
    "\n",
    "        return xdiag or ydiag\n",
    "\n",
    "    def check_layer(self, z):\n",
    "        print(z)\n",
    "        x_checker = any(self.check_x(y, z) for y in range(self.size))\n",
    "        y_checker = any(self.check_y(x, z) for x in range(self.size))\n",
    "        diag_checker = self.check_diagonals(z)\n",
    "\n",
    "        return x_checker or y_checker or diag_checker\n",
    "\n",
    "    def check_cross_diagonals(self):\n",
    "        first = all(self.board[c][c][c] == self.win_player for c in range(self.size))\n",
    "        second = all(self.board[c][(self.size-1) - c][(self.size-1) - c] == self.win_player for c in range(self.size))\n",
    "        third = all(self.board[c][c][(self.size-1) - c] == self.win_player for c in range(self.size))\n",
    "        fourth = all(self.board[c][(self.size-1) - c][c] == self.win_player for c in range(self.size))\n",
    "\n",
    "        return first or second or third or fourth\n",
    "\n",
    "    def check_x(self, y, z):\n",
    "        return all(self.board[x][y][z] == self.win_player for x in range(self.size))\n",
    "\n",
    "    def check_y(self, x, z):\n",
    "        return all(self.board[x][y][z] == self.win_player for y in range(self.size))\n",
    "\n",
    "    def check_diagonals(self, z):\n",
    "        if all(self.board[diag][diag][z] == self.win_player for diag in range(self.size)):\n",
    "            return True\n",
    "\n",
    "        if all(\n",
    "            self.board[(self.size-1) - reverse_diag][reverse_diag][z] == self.win_player\n",
    "            for reverse_diag in range(self.size)\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def check_z(self, x, y):\n",
    "        return all(self.board[x][y][z] == self.win_player for z in range(self.size))\n",
    "\n",
    "    def check_vertical_xdiagonals(self, x):\n",
    "        if all(self.board[x][diag][diag] == self.win_player for diag in range(self.size)):\n",
    "            return True\n",
    "\n",
    "        if all(\n",
    "            self.board[x][reverse_diag][(self.size-1) - reverse_diag] == self.win_player\n",
    "            for reverse_diag in range(self.size)\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "    def check_vertical_ydiagonals(self, y):\n",
    "        if all(self.board[diag][y][diag] == self.win_player for diag in range(self.size)):\n",
    "            return True\n",
    "\n",
    "        if all(\n",
    "            self.board[reverse_diag][y][(self.size-1) - reverse_diag] == self.win_player\n",
    "            for reverse_diag in range(self.size)\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TicTacToe3D(WinCondition):\n",
    "    def __init__(self, render_mode=\"computer\", size=4):\n",
    "        # 3D board: 4 layers of 4x4 grids\n",
    "        super().__init__()\n",
    "        self.size=size\n",
    "        self.board = [[[\" \" for _ in range(self.size)] for _ in range(self.size)] for _ in range(self.size)]\n",
    "        self.current_player = \"X\"\n",
    "        self.players = [\"X\", \"O\"]\n",
    "        self.terminated = False\n",
    "        self.winner = \" \"\n",
    "        self.render_mode = render_mode\n",
    "\n",
    "    def check_draw(self):\n",
    "        # Check for any empty space in the entire 3D board\n",
    "        return not any(\n",
    "            \" \" in self.board[x][y][z]\n",
    "            for x in range(self.size)\n",
    "            for y in range(self.size)\n",
    "            for z in range(self.size)\n",
    "        )\n",
    "\n",
    "    def get_action_space(self):\n",
    "        action_space = []\n",
    "        for x in range(self.size):\n",
    "            for y in range(self.size):\n",
    "                for z in range(self.size):\n",
    "                    if self.board[x][y][z] == \" \":\n",
    "                        action_space.append(self.get_position(x, y, z))\n",
    "\n",
    "        action_space.sort()\n",
    "        return action_space\n",
    "\n",
    "    def print_board(self):\n",
    "        # Prints each layer of the 3D board\n",
    "        for layer in range(self.size):\n",
    "            print(f\"Layer {layer + 1}:\")\n",
    "            print(\"┌───┬───┬───┬───┐\")\n",
    "            for i, row in enumerate(self.board[layer]):\n",
    "                print(\"│ \" + \" │ \".join(row) + \" │\")\n",
    "                if i < self.size-1:\n",
    "                    print(\"├───┼───┼───┼───┤\")\n",
    "            print(\"└───┴───┴───┴───┘\")\n",
    "            if layer < self.size-1:\n",
    "                print()\n",
    "\n",
    "    def create_visualization(self):\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "        for x in range(self.size):\n",
    "            for y in range(self.size):\n",
    "                for z in range(self.size):\n",
    "                    if self.board[x][y][z] == \"X\":\n",
    "                        ax.scatter(x, y, z, color=\"r\", marker=\"o\")\n",
    "                    if self.board[x][y][z] == \"O\":\n",
    "                        ax.scatter(x, y, z, color=\"b\", marker=\"o\")\n",
    "\n",
    "        cmin = 0\n",
    "        cmax = self.size-1\n",
    "\n",
    "        ax.set_xticks(np.arange(cmin, cmax + 1, 1))\n",
    "        ax.set_yticks(np.arange(cmin, cmax + 1, 1))\n",
    "        ax.set_zticks(np.arange(cmin, cmax + 1, 1))\n",
    "\n",
    "        ax.set_xlabel(\"X\")\n",
    "        ax.set_ylabel(\"Y\")\n",
    "        ax.set_zlabel(\"Z\")\n",
    "\n",
    "        if self.winner != \" \":\n",
    "            plt.title(f\"Player {self.winner} Won!\")\n",
    "        else:\n",
    "            plt.title(f\"Player {self.current_player} Turn\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    def change_player(self):\n",
    "        if self.current_player == \"X\":\n",
    "            self.current_player = \"O\"\n",
    "        else:\n",
    "            self.current_player = \"X\"\n",
    "\n",
    "    def get_coordinates(self, position):\n",
    "        x = int((position % (self.size**2) ) % self.size)\n",
    "        y = int((position % (self.size**2) ) / self.size)\n",
    "        z = int(position / (self.size**2) )\n",
    "\n",
    "        return x, y, z\n",
    "\n",
    "    def get_position(self, x, y, z):\n",
    "        return z * (self.size)**2 + y * self.size + x\n",
    "\n",
    "    def update_board(self, x, y, z):\n",
    "        reward = 0\n",
    "\n",
    "        if self.terminated:\n",
    "            return self.board, reward, self.terminated, self.current_player\n",
    "\n",
    "        if self.board[x][y][z] == \" \":\n",
    "            self.board[x][y][z] = self.current_player\n",
    "        else:\n",
    "            self.terminated = True\n",
    "            return self.board, reward, self.terminated, self.current_player\n",
    "\n",
    "        self.win_player = self.current_player\n",
    "        win = self.check_win()\n",
    "        draw = self.check_draw()\n",
    "\n",
    "        self.terminated = win or draw\n",
    "\n",
    "        if win:\n",
    "            if self.current_player == \"X\":\n",
    "                reward = -1\n",
    "                self.winner = \"X\"\n",
    "            else:\n",
    "                reward = 1\n",
    "                self.winner = \"O\"\n",
    "        elif draw:\n",
    "            reward = 0\n",
    "\n",
    "        self.change_player()\n",
    "\n",
    "        return self.board, reward, self.terminated, self.current_player\n",
    "\n",
    "    def step_coordinates(self, x, y, z):\n",
    "        # Output: Observation, reward, terminated, player_turn\n",
    "        observation, reward, terminated, player_turn = self.update_board(x, y, z)\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.create_visualization()\n",
    "\n",
    "        return observation, reward, terminated, player_turn\n",
    "\n",
    "    def step(self, position):\n",
    "        # Output: Observation, reward, terminated, player_turn\n",
    "        x, y, z = self.get_coordinates(position)\n",
    "        observation, reward, terminated, player_turn = self.update_board(x, y, z)\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.create_visualization()\n",
    "\n",
    "        return observation, reward, terminated, player_turn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = TicTacToe3D(size=3, render_mode=\"human\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = [\"State\", \"Action\", \"QValue\"]\n",
    "with open(\"QTable.csv\", \"a\", newline=\"\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(row)\n",
    "    # f.write([\"State\", \"Action\", \"QValue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_processed_observation_to_board(processed_observation, size):\n",
    "    board = [[[\" \" for _ in range(size)] for _ in range(size)] for _ in range(size)]\n",
    "    for i, char in enumerate(processed_observation):\n",
    "        x = int((i % (size**2)) % size)\n",
    "        y = int((i % (size**2)) / size)\n",
    "        z = int(i / (size**2))\n",
    "\n",
    "        board[z][y][x] = char\n",
    "\n",
    "    return board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_observations(observation):\n",
    "    # Flatten the 3-dimensional list\n",
    "    flattened_list = [\n",
    "        item\n",
    "        for sublist in [inner for outer in observation for inner in outer]\n",
    "        for item in sublist\n",
    "    ]\n",
    "    processed = \"\".join(flattened_list)\n",
    "\n",
    "    return processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table = {}\n",
    "\n",
    "actions = env.get_action_space()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_value = {}\n",
    "for action in actions:\n",
    "    action_value[action] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "Q_table[state] = action_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QLearning:\n",
    "    def __init__(self, map_size, gamma=1, number_of_iterations=100000):\n",
    "        # super().__init__(map_size, gamma)\n",
    "        self.map_size = map_size\n",
    "        self.number_of_iterations = number_of_iterations\n",
    "\n",
    "        self.Q_table = {}\n",
    "\n",
    "\n",
    "        self.alphas = self.get_parameters_exponential_decay(decay_rate=0.99995)\n",
    "\n",
    "\n",
    "\n",
    "    def epsilon_greedy_exponential(self, iteration, state):\n",
    "        # epsilon = self.epsilons[iteration]\n",
    "\n",
    "        epsilon = 0.5\n",
    "        selected_action = 0\n",
    "        if np.random.random() > epsilon:\n",
    "            selected_action = self.Q_table[state].argmax()\n",
    "        else:\n",
    "            selected_action = np.random.randint(len(self.Q_table[state]))\n",
    "\n",
    "        return selected_action\n",
    "\n",
    "    def get_parameters_exponential_decay(\n",
    "        self, initial_value=1, min_value=0.01, decay_rate=0.99\n",
    "    ):\n",
    "        num_points = self.number_of_iterations\n",
    "\n",
    "        exponential_decay_parameters = initial_value * (\n",
    "            decay_rate ** np.arange(num_points)\n",
    "        )\n",
    "        exponential_decay_parameters = np.where(\n",
    "            exponential_decay_parameters < min_value,\n",
    "            min_value,\n",
    "            exponential_decay_parameters,\n",
    "        )\n",
    "\n",
    "        return exponential_decay_parameters\n",
    "\n",
    "\n",
    "    def do_one_qlearning_iteration(self, iteration, gamma=0.99):\n",
    "        terminated = 0\n",
    "        truncated = 0\n",
    "\n",
    "        env = TicTacToe3D(size=3)\n",
    "        current_state = 0\n",
    "        action = self.epsilon_greedy_exponential(iteration, current_state)\n",
    "\n",
    "        trajectory = []\n",
    "\n",
    "        observation, _ = env.reset()\n",
    "        while not terminated and not truncated:\n",
    "            observation, reward, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "            next_state = observation\n",
    "            next_action = self.epsilon_greedy_exponential(iteration, next_state)\n",
    "\n",
    "            self.Q_table[current_state][action] = self.Q_table[current_state][\n",
    "                action\n",
    "            ] + self.alphas[iteration] * (\n",
    "                reward\n",
    "                + gamma * max(self.Q_table[next_state])\n",
    "                - self.Q_table[current_state][action]\n",
    "            )\n",
    "\n",
    "            current_state = next_state\n",
    "            action = next_action\n",
    "\n",
    "            trajectory.append((current_state, action))\n",
    "\n",
    "        return trajectory\n",
    "\n",
    "    def do_qlearning(self):\n",
    "        for i in tqdm(range(self.number_of_iterations)):\n",
    "            trajectory = self.do_one_qlearning_iteration(i)\n",
    "            self.trajectories.append(trajectory)\n",
    "            self.Q_track[i] = self.Q_table\n",
    "\n",
    "        self.build_tables()\n",
    "\n",
    "    def build_tables(self):\n",
    "        optimal_policy = np.argmax(ql.Q_table, axis=1)\n",
    "\n",
    "        for state in range(16):\n",
    "            if state in terminal_states:\n",
    "                optimal_policy[state] = -1\n",
    "            if state == 15:\n",
    "                optimal_policy[state] = -2\n",
    "\n",
    "        self.optimal_policy = optimal_policy\n",
    "        self.value_table = np.max(self.Q_table, axis=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
